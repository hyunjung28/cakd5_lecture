{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "685d000b",
   "metadata": {},
   "source": [
    "###  앙상블 학습\n",
    "\n",
    "* 앙상블 학습의 유형은 보팅, 배깅, 부스팅 세가지로 나눌 수 있으며 이외에도 스태깅을 포함한 다양한 앙상블 방법이 있다.\n",
    "* 보팅의 경우 서로 다른 알고리즘을 가진 분류기를 결합하는 것이고 배깅의 경우 각각의 분류기각 모두 같은 유형의 알고리즘 기반이다.\n",
    "* 정형 데이터의 예측 분석 영역에서는 매우 높은 예측 성능. Bagging 과 Boosting\n",
    "* 배깅 방식의 대표인 Random Forest는 뛰어난 예측 성능, 상대적으로 빠른 수행시간, 유연성 등으로 애용.\n",
    "* 부스팅의 효시는 Gradient Boosting, 한 단계 발전시키면서도 시간 단축시킨 XgBoost, LightGBM이 정형 데이터의 분류 영역에서 \n",
    "  활용도 확대\n",
    "* 앙상블의 앙상블이라고 불리는 스태킹 기법\n",
    "* 앙상블의 기본 알고리즘은 결정 트리\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3f939fd",
   "metadata": {},
   "source": [
    "Voting Classifier\n",
    "\n",
    "- 하드 보팅: 다수결 원칙, 다수의 분류기가 결정한 예측값을 최종 보팅 결과값으로 선정\n",
    "- 소프트 보팅: 분류기들의 레이블 값 결정 확률을 모두 더해서 평균하고 이들 중 가장 높은 레이블 값을 최종 보팅 결과값으로 선정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d59369bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean radius</th>\n",
       "      <th>mean texture</th>\n",
       "      <th>mean perimeter</th>\n",
       "      <th>mean area</th>\n",
       "      <th>mean smoothness</th>\n",
       "      <th>mean compactness</th>\n",
       "      <th>mean concavity</th>\n",
       "      <th>mean concave points</th>\n",
       "      <th>mean symmetry</th>\n",
       "      <th>mean fractal dimension</th>\n",
       "      <th>...</th>\n",
       "      <th>worst radius</th>\n",
       "      <th>worst texture</th>\n",
       "      <th>worst perimeter</th>\n",
       "      <th>worst area</th>\n",
       "      <th>worst smoothness</th>\n",
       "      <th>worst compactness</th>\n",
       "      <th>worst concavity</th>\n",
       "      <th>worst concave points</th>\n",
       "      <th>worst symmetry</th>\n",
       "      <th>worst fractal dimension</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>0.07871</td>\n",
       "      <td>...</td>\n",
       "      <td>25.38</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>0.05667</td>\n",
       "      <td>...</td>\n",
       "      <td>24.99</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>0.05999</td>\n",
       "      <td>...</td>\n",
       "      <td>23.57</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>0.09744</td>\n",
       "      <td>...</td>\n",
       "      <td>14.91</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>0.05883</td>\n",
       "      <td>...</td>\n",
       "      <td>22.54</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean radius  mean texture  mean perimeter  mean area  mean smoothness  \\\n",
       "0        17.99         10.38          122.80     1001.0          0.11840   \n",
       "1        20.57         17.77          132.90     1326.0          0.08474   \n",
       "2        19.69         21.25          130.00     1203.0          0.10960   \n",
       "3        11.42         20.38           77.58      386.1          0.14250   \n",
       "4        20.29         14.34          135.10     1297.0          0.10030   \n",
       "\n",
       "   mean compactness  mean concavity  mean concave points  mean symmetry  \\\n",
       "0           0.27760          0.3001              0.14710         0.2419   \n",
       "1           0.07864          0.0869              0.07017         0.1812   \n",
       "2           0.15990          0.1974              0.12790         0.2069   \n",
       "3           0.28390          0.2414              0.10520         0.2597   \n",
       "4           0.13280          0.1980              0.10430         0.1809   \n",
       "\n",
       "   mean fractal dimension  ...  worst radius  worst texture  worst perimeter  \\\n",
       "0                 0.07871  ...         25.38          17.33           184.60   \n",
       "1                 0.05667  ...         24.99          23.41           158.80   \n",
       "2                 0.05999  ...         23.57          25.53           152.50   \n",
       "3                 0.09744  ...         14.91          26.50            98.87   \n",
       "4                 0.05883  ...         22.54          16.67           152.20   \n",
       "\n",
       "   worst area  worst smoothness  worst compactness  worst concavity  \\\n",
       "0      2019.0            0.1622             0.6656           0.7119   \n",
       "1      1956.0            0.1238             0.1866           0.2416   \n",
       "2      1709.0            0.1444             0.4245           0.4504   \n",
       "3       567.7            0.2098             0.8663           0.6869   \n",
       "4      1575.0            0.1374             0.2050           0.4000   \n",
       "\n",
       "   worst concave points  worst symmetry  worst fractal dimension  \n",
       "0                0.2654          0.4601                  0.11890  \n",
       "1                0.1860          0.2750                  0.08902  \n",
       "2                0.2430          0.3613                  0.08758  \n",
       "3                0.2575          0.6638                  0.17300  \n",
       "4                0.1625          0.2364                  0.07678  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "cancer = load_breast_cancer()\n",
    "data_df = pd.DataFrame(cancer.data,columns=cancer.feature_names)\n",
    "data_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2c126f24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Voting 분류기 정확도 0.9473684210526315\n",
      "LogisticRegression정확도:0.9386\n",
      "KNeighborsClassifier정확도:0.9386\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "#개별 모델은 로지스틱 회귀와 KNN임\n",
    "lr_clf = LogisticRegression()\n",
    "knn_clf = KNeighborsClassifier(n_neighbors=8)\n",
    "vo_clf = VotingClassifier(estimators=[('LR',lr_clf),('KNN',knn_clf)],voting='soft')\n",
    "X_train,X_test,y_train,y_test = train_test_split(cancer.data,cancer.target,test_size=0.2,random_state=156)\n",
    "#Voting-> 다른 알고리즘 사용해서 그 중 평균값 내서 최종 투표한 걸로 선택\n",
    "vo_clf.fit(X_train,y_train)\n",
    "pred= vo_clf.predict(X_test)\n",
    "print('Voting 분류기 정확도',accuracy_score(y_test,pred))\n",
    "#개별 모델의 학습.예측.평가\n",
    "classifiers = [lr_clf,knn_clf]\n",
    "for classifier in classifiers:\n",
    "    classifier.fit(X_train,y_train)\n",
    "    pred = classifier.predict(X_test)\n",
    "    class_name = classifier.__class__.__name__\n",
    "    print('{0}정확도:{1:.4f}'.format(class_name,accuracy_score(y_test,pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abc48729",
   "metadata": {},
   "source": [
    "https://eunsukimme.github.io/ml/2019/11/26/Random-Forest/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c263d93d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_new_feature_name_df(old_feature_name_df):\n",
    "    feature_dup_df = pd.DataFrame(data=old_feature_name_df.groupby('column_name').cumcount(),\n",
    "                                 columns=['dup_cnt'])\n",
    "    feature_dup_df = feature_dup_df.reset_index() \n",
    "    new_feature_name_df = pd.merge(old_feature_name_df.reset_index(),feature_dup_df,how='outer')\n",
    "    new_feature_name_df['column_name'] = new_feature_name_df[['column_name',\n",
    "                                                             'dup_cnt']].apply(lambda x:x[0]+'_'+str(x[1])\n",
    "                                                                              if x[1]>0 else x[0], axis=1)\n",
    "    new_feature_name_df = new_feature_name_df.drop(['index'],axis=1)\n",
    "    return new_feature_name_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1b045112",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_human_dataset():\n",
    "    feature_name_df = pd.read_csv('dataset/human_activity/features.txt', sep='\\s+', header=None, \\\n",
    "                              names = ['column_index','column_name'])\n",
    "    \n",
    "    new_feature_name_df = get_new_feature_name_df(feature_name_df)\n",
    "    \n",
    "    feature_name = new_feature_name_df.iloc[:,1].values.tolist()\n",
    "    \n",
    "    X_train = pd.read_csv('dataset/human_activity/train/X_train.txt', sep='\\s+', header=None)\n",
    "    X_train.columns = feature_name\n",
    "    X_test = pd.read_csv('dataset/human_activity/test/X_test.txt', sep='\\s+', header=None)\n",
    "    X_test.columns = feature_name\n",
    "    \n",
    "    y_train = pd.read_csv('dataset/human_activity/train/y_train.txt', sep='\\s+', header=None, names=['action'])\n",
    "    y_test = pd.read_csv('dataset/human_activity/test/y_test.txt', sep='\\s+', header=None, names=['action'])\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test\n",
    "X_train, X_test, y_train, y_test = get_human_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ad6d16de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "랜덤 포레스트 정확도 0.9253478113335596\n"
     ]
    }
   ],
   "source": [
    "# 보깅-> 보팅과는 다르게 같은 알고리즘을 사용, 랜덤포레스트가 대표적인 보깅 방식\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "X_train,X_test,y_train,y_test = get_human_dataset()\n",
    "\n",
    "rf_clf = RandomForestClassifier(random_state=0)\n",
    "rf_clf.fit(X_train,y_train)\n",
    "pred = rf_clf.predict(X_test)\n",
    "accuracy = accuracy_score(y_test,pred)\n",
    "print('랜덤 포레스트 정확도',accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "47018817",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_depth': 10, 'min_samples_leaf': 8, 'min_samples_split': 8, 'n_estimators': 100}\n",
      "테스트 데이터에서 정확도: 0.920\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "params= {\n",
    "    'n_estimators':[50,100],\n",
    "    'max_depth':[6,8,10,12],\n",
    "    'min_samples_leaf':[8,12,18],\n",
    "    'min_samples_split':[8,16,20]\n",
    "}\n",
    "\n",
    "#훈련용 데이터로 학습\n",
    "rf_clf = RandomForestClassifier(random_state=0,n_jobs=-1)\n",
    "grid_cv = GridSearchCV(rf_clf,param_grid =params,cv=2,n_jobs=-1)\n",
    "grid_cv.fit(X_train,y_train)\n",
    "pred = grid_cv.predict(X_test)\n",
    "accuracy = accuracy_score(y_test,pred)\n",
    "print(grid_cv.best_params_)\n",
    "\n",
    "\n",
    "#테스트 데이터로 예측평가\n",
    "y_pred = grid_cv.best_estimator_.predict(X_test)\n",
    "accuracy_test = accuracy_score(y_test , y_pred)\n",
    "print('테스트 데이터에서 정확도: {0:.3f}'.format(accuracy_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9d6d1131",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_depth': 10, 'min_samples_leaf': 8, 'min_samples_split': 4, 'n_estimators': 150}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "params= {\n",
    "    'n_estimators':[100,150],\n",
    "    'max_depth':[6,8,10,12],\n",
    "    'min_samples_leaf':[4,6,8],\n",
    "    'min_samples_split':[4,6,8]\n",
    "}\n",
    "rf_clf = RandomForestClassifier(random_state=0,n_jobs=-1)\n",
    "grid_cv = GridSearchCV(rf_clf,param_grid =params,cv=2,n_jobs=-1)\n",
    "grid_cv.fit(X_train,y_train)\n",
    "\n",
    "print(grid_cv.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23c74d77",
   "metadata": {},
   "outputs": [],
   "source": [
    "#변수 중요도 시각화\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "ftr_importances_values = rf_clf.feature_importances_\n",
    "ftr_importances = pd.Series(ftr_importances_values,index=X_train.columns)\n",
    "ftr_top20 = ftr_importances.sort_values(ascending=False)[:20]\n",
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "plt.title('feature importance top 20')\n",
    "sns.barplot(x=ftr_top20,y = ftr_top20.index)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f707b2b",
   "metadata": {},
   "source": [
    "### GBM(Gradient Boosting Machine)\n",
    "- 부스팅 알고리즘은 여러 개의 약한 학습기(weak learner)를 순차적으로 학습-예측하면서 잘못 예측한 데이터에 가중치 부여를 통해 오류를 개선해 나가면서 학습하는 방식\n",
    "- 가중치 업데이트를 경사 하강법(Gradient Descent)를 이용한다.\n",
    "- 분류는 물론이고 회귀도 가능\n",
    "- 파라미터 : n_estimators, max_depth, max_features\n",
    " - loss : 경사하강법에서 사용할 비용함수 지정. 기본값 deviance 적용\n",
    " - learning_rate : GBM이 학습할 때마다 적용할 학습률.오류값 보정 시 적용하는 계수로 0 ~ 1 사이의 값 지정. 기본값은 0.1. 작게 설정하면 예측성능이 높아지나 수행시간이 오래 걸리고 큰 값을 적용하면 예측 성능이 떨어질 가능성이 높으나 빠른 수행이 가능. n_estimator와 상호 보완적으로 조합해 사용\n",
    " - n_estimator : weak learner의 개수\n",
    " - subsample : weak learner가 학습에 사용하는 데이터의 샘플링 비율. 기본값은 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "831763b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "import time\n",
    "\n",
    "X_train,X_test,y_train,y_test = get_human_dataset()\n",
    "\n",
    "start_time = time.time()\n",
    "gb_clf = GradientBoostingClassifier(random_state=0)\n",
    "gb_clf.fit(X_train,y_train)\n",
    "gb_pred = gb_clf.predict(X_test)\n",
    "gb_accuracy = accuracy_score(y_test,gb_pred)\n",
    "\n",
    "print('GBM 정확도',gb_accuracy)\n",
    "print('GBM 수행 시간',time.time()-strat_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86b9da77",
   "metadata": {},
   "outputs": [],
   "source": [
    "#[과제]상기 케이스에 대하여 성능개선을 위한 튜닝을 수행하세요.\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "params={\n",
    "    'n_estimators':[100,500],\n",
    "    'learning_rate':[0.05,1]\n",
    "}\n",
    "gird_cv = GridSearchCV(gb_clf,param_grid =prarams,cv=2,verbose=1)\n",
    "grid_cv.fit(X_trian,y_train)\n",
    "pred = grid_cv.predict(X_test)\n",
    "accuracy = accuracy_score(y_test,pred)\n",
    "print('최적 하이터 파라미터',gird_cv.best_params_)\n",
    "print('최고 예측 정확도',gird_cv.best_score_)\n",
    "print('GBM정확도',accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fa2e426",
   "metadata": {},
   "outputs": [],
   "source": [
    "gb_clf =grid_cv.best_estimator_.predict(X_test)\n",
    "#안에 파라미터는 하이터 파라미터 값으로 \n",
    "gb_clf.fit(X_train,y_train,early_stopping_rounds=100,eval_metric='auc',eval_set=evals,verbose=True)\n",
    "gb_roc_score = roc_auc_score(y_test,gb_clf.predict_proba(X_test)[:,1],average='macro')\n",
    "print('lgbm_roc_score',gb_roc_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73640db0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "#개별 모델은 로지스틱 회귀와 KNN임\n",
    "lr_clf = LogisticRegression()\n",
    "knn_clf = KNeighborsClassifier(n_neighbors=8)\n",
    "vo_clf = VotingClassifier(estimators=[('LR',lr_clf),('KNN',knn_clf)],voting='soft')\n",
    "X_train,X_test,y_train,y_test = train_test_split(cancer.data,cancer.target,test_size=0.2,random_state=156)\n",
    "#Voting-> 다른 알고리즘 사용해서 그 중 평균값 내서 최종 투표한 걸로 선택\n",
    "vo_clf.fit(X_train,y_train)\n",
    "pred= vo_clf.predict(X_test)\n",
    "print('Voting 분류기 정확도',accuracy_score(y_test,pred))\n",
    "#개별 모델의 학습.예측.평가\n",
    "classifiers = [lr_clf,knn_clf]\n",
    "for classifier in classifiers:\n",
    "    classifier.fit(X_train,y_train)\n",
    "    pred = classifier.predict(X_test)\n",
    "    class_name = classifier.__class__.__name__\n",
    "    print('정확도',class_name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
